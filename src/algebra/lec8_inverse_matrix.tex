\begin{definition}
    \label{d:inverse matrix}
    Macierz odwrotna $A^{-1}$ do macierzy kwadratowej $A_{n\times n}$ to taka macierz, że
    \[ A\cdot A^{-1} = A^{-1}\cdot A = I_n. \]
    Jeśli taka macierz istnieje, to mówimy, że $A$ jest macierzą \vocab{odwracalną}.
\end{definition}

\begin{theorem}
    \label{t:invertible matrix}
    Jeśli macierz $A_{n\times n}$ jest odwracalna, to
    \begin{enumerate}
        \item $\det A \neq 0$ oraz $\det (A^{-1}) = (\det A)^{-1}$,
        \item $A^{-1} = \frac{1}{\det A} (A^D)^T$, gdzie $A^D$ jest macierzą dopełnień algebraicznych $A_{ij}$ macierzy $A$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    \begin{enumerate}
        \item Z definicji macierzy odwrotnej (\ref{d:inverse matrix})
            \[ \begin{aligned} A\cdot A^{-1} &= I \\
                         \det(A\cdot A^{-1}) &= \det I = 1.
            \end{aligned} \]
            Na mocy twierdzenia Cauchy'ego (\ref{t:det is multiplicative}) otrzymujemy
            \[ \det A \cdot \det (A^{-1}) = 1, \]
            z czego wynika teza.
        \item Weźmy macierz $B$ taką, że
            \[ B = \frac{1}{\det A} (A^D)^T, \]
            to znaczy, że dla każdego $i,j$ zachodzi
            \[ b_{ij} = \det A^{-1} \cdot A_{ji}, \]
            Obliczmy teraz macierz $C = AB$:
            \[ \begin{aligned}
                c_{ij} &= \sum_{k=1}^n a_{ik} b_{kj} \\
                       &= \sum_{k=1}^n a_{ik}\cdot\det A^{-1}\cdot A_{jk} \\
                       &= \det A^{-1}\sum_{k=1}^n a_{ik}\cdot A_{jk}.
            \end{aligned} \]
            Jeśli $i = j$, to z rozwinięcia Laplace'a (\ref{t:Laplace}) wzdłuż $i$-tego rzędu otrzymujemy
            \[ c_{ij} = \det A^{-1} \cdot \det A = 1, \]
            w przeciwnym wypadku rozwijamy macierz, która ma dwa takie same rzędy ($i$-ty oraz $j$-ty), więc jej wyznacznik jest zerowy, stąd
            \[ c_{ij} = 0. \]
            Z tego wynika, że $C$ jest macierzą jednostkową, więc $B = A^{-1}$.
    \end{enumerate}
\end{proof}

\begin{definition}
    Macierz osobliwa to macierz $A$, której wyznacznik jest zerowy. W innym wypadku $A$ jest macierzą nieosobliwą.
\end{definition}

Na podstawie twierdzenia \ref{t:invertible matrix} łatwo zauważyć, że pojęcie macierzy nieosobliwej jest równoznaczne macierzy odwracalnej, a macierzy osobliwej --- nieodwracalnej. Ponadto, jeśli macierz $A_{n\times n}$ jest nieosobliwa, to $\rank A = n$, a $A^{-1}, A^T, \alpha A, A^n$ również są macierzami nieosobliwymi.

Aby znaleźć macierz odwrotną, można oczywiście wykorzystać wzór
\[ A^{-1} = \frac{1}{\det A}(A^D)^T \]
z twierdzenia \ref{t:invertible matrix}, ale zwykle szybszą\footnote{na pewno w sensie złożoności obliczeniowej, w zadaniach to kwestia preferencji} metodą będzie eliminacja Gaussa, którą możemy wykorzystać wraz z poniższym faktem.

\begin{fact}
    Jeśli macierz kwadratowa $A$ jest odwracalna, to
    \[ \begin{bNiceArray}{cSc}A & I\end{bNiceArray} \sim \begin{bNiceArray}{cSc}I & B\end{bNiceArray} \quad\implies\quad B = A^{-1}. \]
\end{fact}
\begin{proof}
    Aby zrozumieć poniższy dowód trzeba się zapoznać z treścią sekcji \nameref{s:linear map}.

    Łatwo udowodnić, że każda operacja elementarna może być rozumiana jako pewne odwzorowanie liniowe, a tym samym --- jako operacja pomnożenia przez pewną macierz (odwzorowania liniowego). Drugi fakt, z którego należy sobie zdać sprawę, to równość
    \[ X\begin{bNiceArray}{cSc}A & I\end{bNiceArray} = \begin{bNiceArray}{cSc}XA & XI\end{bNiceArray}, \]
    która wynika bezpośrednio z definicji mnożenia macierzy. Z tych dwóch stwierdzeń wynika
    \[ \begin{bNiceArray}{cSc}A & I\end{bNiceArray} \sim \begin{bNiceArray}{cSc}X_1A & X_1I\end{bNiceArray} \sim \begin{bNiceArray}{cSc}X_2X_1A & X_2X_1I\end{bNiceArray} \sim \ldots \sim \begin{bNiceArray}{cSc}A^{-1}A & A^{-1}I\end{bNiceArray} = \begin{bNiceArray}{cSc}I & A^{-1}\end{bNiceArray}, \]
    gdzie $A^{-1}$ jest niejako ciągiem odwzorowań liniowych $X_i$, które wykonujemy podczas eliminacji Gaussa.
\end{proof}

\begin{example}
    \label{ex:inverse matrix}
    Znaleźć macierz odwrotną do macierzy
    \[ A = \begin{bmatrix}
        1 & 4 & 6 \\
        2 & 5 & 3 \\
        0 & 1 & 4
    \end{bmatrix}. \]
\end{example}
\begin{solution}
    \begin{align*}
        &\begin{bNiceArray}{cccIccc}
            1 & 4 & 6 & 1 & 0 & 0 \\
            2 & 5 & 3 & 0 & 1 & 0 \\
            0 & 1 & 4 & 0 & 0 & 1
        \end{bNiceArray} \sim \begin{bNiceArray}{cccIccc}
            1 & 4 & 6 & 1 & 0 & 0 \\
            0 & -3 & -9 & -2 & 1 & 0 \\
            0 & 1 & 4 & 0 & 0 & 1
        \end{bNiceArray} \sim \begin{bNiceArray}{cccIccc}
            1 & 4 & 6 & 1 & 0 & 0 \\
            0 & 1 & 3 & \frac{2}{3} & \frac{-1}{3} & 0 \\
            0 & 1 & 4 & 0 & 0 & 1
        \end{bNiceArray} \\ \sim &\begin{bNiceArray}{cccIccc}
            1 & 4 & 6 & 1 & 0 & 0 \\
            0 & 1 & 3 & \frac{2}{3} & \frac{-1}{3} & 0 \\
            0 & 0 & 1 & \frac{-2}{3} & \frac{1}{3} & 1
        \end{bNiceArray} \sim \begin{bNiceArray}{cccIccc}
            1 & 0 & -6 & \frac{-5}{3} & \frac{4}{3} & 0 \\
            0 & 1 & 3 & \frac{2}{3} & \frac{-1}{3} & 0 \\
            0 & 0 & 1 & \frac{-2}{3} & \frac{1}{3} & 1
        \end{bNiceArray} \sim \begin{bNiceArray}{cccIccc}
            1 & 0 & -6 & \frac{-5}{3} & \frac{4}{3} & 0 \\
            0 & 1 & 0 & \frac{8}{3} & \frac{-4}{3} & -3 \\
            0 & 0 & 1 & \frac{-2}{3} & \frac{1}{3} & 1
        \end{bNiceArray} \\ \sim &\begin{bNiceArray}{cccIccc}
            1 & 0 & 0 & \frac{-17}{3} & \frac{10}{3} & 6 \\
            0 & 1 & 0 & \frac{8}{3} & \frac{-4}{3} & -3 \\
            0 & 0 & 1 & \frac{-2}{3} & \frac{1}{3} & 1
        \end{bNiceArray},
    \end{align*}
    a więc
    \[ A^{-1} = \frac{1}{3}\begin{bmatrix}
                            -17 & 10 & 18 \\
                            8 & -4 & -9 \\
                            -2 & 1 & 3
    \end{bmatrix}. \]

    Możemy zweryfikować swoje obliczenia, znajdując macierz odwrotną metodą macierzy dopełnień algebraicznych.
    \begin{align*} A^{-1} &= \frac{1}{5 \cdot 4 + 6 \cdot 2 - 4 \cdot 2 \cdot 4 - 3}\begin{bmatrix}
            5 \cdot 4 - 3 & -(2 \cdot 4) & 2 \\
            -(4 \cdot 4 - 6) & 4 & -(1) \\
            4 \cdot 3 - 6 \cdot 5 & -(3 - 6 \cdot 2) & 5 - 4 \cdot 2
        \end{bmatrix}^T \\ &= \frac{1}{-3}\begin{bmatrix}
            17 & -8 & 2 \\
            -10 & 4 & -1 \\
            -18 & 9 & -3
        \end{bmatrix}^T = \frac{1}{3}\begin{bmatrix}
            -17 & 10 & 18 \\
            8 & 4 & 9 \\
            -2 & 1 & 3
        \end{bmatrix}.
    \end{align*}
\end{solution}

Macierz odwrotną można znaleźć również rozwiązując układ równań liniowych
\[ A \cdot X = B, \]
wtedy $A^{-1} \cdot B = X$ --- o czym więcej w następnej sekcji.